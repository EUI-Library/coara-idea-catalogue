---
title: "Reducing frequency of assessment"
author: "Experiments in Assessment WG"
date: "2025-03-03"
categories: [Level 0, Challenge - Process, Challenge - Process Culture, Challenge - Different Questions, CoARA Commitment 2, CoARA Commitment 6, User - Funder, User - Institutes]
description: "Reducing how frequently researchers are assessed, for example by requiring fewer assessment during their career or by increasing the funding periods."
image: false
---

<!--
GENERAL GUIDELINES:
- Use this guide to style all text: https://quarto.org/docs/authoring/markdown-basics.html
- Tags (apply as relevant):
Level 0 = Level of completeness: 0 – The experiment only contains the description and minimal details. This level is meant to provide inspiration for experiments that can be developed further by those experimenting.
Level 1 = Level of completeness: 1 –  The experiment contains minimal details. Organisations will need to build the experimentation plan before they can implement the idea.
Level 2 = Level of completeness: 2 – The experiment contains minimal details that may help with the design and implementation, but organisations will need to build most of the experimentation plan before they can fully implement the idea.
Level 3 = Level of completeness: 3 – The experiment contains some details that may help with the design and implementation, but organisations will need to finalise the experimentation plan before they can fully implement the idea.
Level 4 = Level of completeness: 4 – The experiment contains details that can provide useful guidance for implementation, but additional research will need to be done by experimenting organisation. Few real life cases exist. 
Level 5 = Level of completeness: 5 – The experiment contains sufficient details to be implemented, and it has already been experimented in some organisations providing cases, additional suggestions, and often learned lessons. 
Challenge - Process = Create an assessment process based upon what the different players in research value
Challenge - Inclusivity = Make research more inclusive and equitable through assessment
Challenge - Bias Mitigation = Mitigate the negative effects of bias on assessment
Challenge - Process Culture = Recognize process and culture through assessment
Challenge - Diversity = Foster diversity through assessment
Challenge - Collaboration = Foster collaboration through assessment
Challenge - Different Questions = Ask assessment questions differently
CoARA Commitment 1 = Recognise the diversity of contributions to, and careers in, research in accordance with the needs and nature of the research
CoARA Commitment 2 = Base research assessment primarily on qualitative evaluation for which peer review is central, supported by responsible use of quantitative indicators
CoARA Commitment 3 = Abandon inappropriate uses in research assessment of journal- and publication-based metrics, in particular inappropriate uses of Journal Impact Factor (JIF) and h-index
CoARA Commitment 4 = Avoid the use of rankings of research organisations in research assessment
CoARA Commitment 5 = Commit resources to reforming research assessment as is needed to achieve the organisational changes committed to
CoARA Commitment 6 = Review and develop research assessment criteria, tools and processes
CoARA Commitment 7 = Raise awareness of research assessment reform and provide transparent communication, guidance, and training on assessment criteria and processes as well as their use
CoARA Commitment 8 = Exchange practices and experiences to enable mutual learning within and beyond the Coalition
CoARA Commitment 9 = Communicate progress made on adherence to the Principles and implementation of the Commitments
CoARA Commitment 10 = Evaluate practices, criteria and tools based on solid evidence and the state-of-the-art in research on research, and make data openly available for evidence gathering and research
User - Funder = User could involve Funders and regional authorities
User - Institutes = User could involve Research institutions
User - Academies = User could involve Academies and learned societies
User - Research Groups = User could involve Research groups
User - Meta-Researchers = User could involve Meta-researchers
User - Scientific editors and publishers = User could involve Scientific editors and publishers
-->

::: {.callout-warning icon=false}

## Objectives and potential outcome
<!--
PROMPTS:
- What happens if this is successful? What changes if this works? 
- What improvements are we aiming for?
- These can be related to the main questions
- If there are multiple experiments fitting, put them here
-->

Reducing the frequency of assessment is meant to give room for higher quality assessment by enabling applicants to spend more time preparing fewer high quality applications rather than focusing on a high volume of frequently recurring applications and by freeing time from reviewers for more in-depth evaluations. 


:::

## Research domains
<!--
PROMPTS:
- Which domain(s) can this experiment be applied in? 
-->

This would involve looking at the assessments currently in place and questionning whether they are really needed. This may apply especially in research institutions where repeated assessments for promotion and employment continuation generally take place. This could also relate to streamlining assessments or changing the intensity of assessment.  

## Context and considerations
<!--
PROMPTS:
- Who is carrying out the evaluation? Who is this experiment for? (i.e., Target groups - Funders? Institutions? Individual researchers? Research domains?); 
- What type of assessment does this work on (Team/individual/project/institutional);
- What is the objective of evaluation exercise linked to the type of assessment
- What are the things that change in the experiment?
- Nature of the organization carrying out evaluation exercise; What type of assessment (Team/individual/project/institutional); Objective of evaluation exercise linked to the type of assessment
-->

This would generally imply reducing how frequently researchers are assessed either by increasing the funding periods or by increasing employment duration, but it could also imply shifting the focus of intensity (full CV vs focus on one element of the process to provide feedback on selected elements) so the evaluation takes a lighter touch. For funders, this could also be part of lighter audit report requiremewnts and shifting the assessment to provide feedback rather than being based solely as an evaluative exercise.

## Challenges and mitigations
<!--
PROMPTS:
- Each challenge and mitigation grouped together
- If there isn’t mitigation, say so
- Tips and tricks for preparing and running the experiment
-->
**Certain challenges include:**  
- Could lead to bigger implications for not performing well  
- Reducing the frequency of career assessment may also reduce the frequency of constructive feedback  
- For Funders: giving longer grants could reduce assessment frequency but also leads to higher stakes

## Evaluating success
<!--
PROMPTS:
- Evaluation criteria for the experiment 
- How do you know it worked or didn’t?
-->

## Related CoARA commitments
<!--
PROMPTS:
Directly reference as many of the 10 CoARA commitments as are fitting
-->

# Relevant resources and literature 

The SCOPE Framework for Research Evaluation mentions how crucial it is to "Evaluate only where necessary", stressing that evaluation is not always the right strategy, especially when the desired outcome is a behaviour change. <https://inorms.net/scope-framework-for-research-evaluation/>

## Templates from funders and institutions 
<!--
PROMPTS:
- Add templates from funders and institutions if existing
-->

## Case examples and literature
<!--
PROMPTS:
Any organisation names, links, authors that may be relevant to look into
-->

In their new career and evaluation policy for professional staff, Ghent University mentioned that one of their core achievements was to reduce the frequency of assessment to five years, mentioning that the higher frequency of assessment from the previous evaluation policy "put a high administrative burden on the professors and faculty staff, with a lot of paperwork to fill in, at a high evaluation frequency". More information on their motivation for change is available in the DORA case study they detailed in 2020. <https://sfdora.org/case-study/ghent-university/>

## Other resources
<!--
PROMPTS:
Include any other resource here
-->


# Comments/lived examples
<!--
PROMPTS:
Section to be kept blank, for input within the idea catalogue
-->




